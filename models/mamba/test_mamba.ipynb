{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUMMY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size = 5\n",
    "feature_dim = 37\n",
    "length_time = 50\n",
    "\n",
    "data = torch.randn(batch_size, feature_dim, length_time)\n",
    "time = torch.randint(0, 500, (1, length_time))\n",
    "data_1 = data[0]\n",
    "\n",
    "\n",
    "static = torch.randn(batch_size, 8)\n",
    "static_1 = static[0]\n",
    "    \n",
    "sensor_mask = torch.zeros(batch_size, feature_dim, length_time)\n",
    "\n",
    "sensor_mask[0, :10] = 1\n",
    "sensor_mask[1, :20] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SENSOR EMBEDDING LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Output Shape: torch.Size([37, 50, 32])\n",
      "Embedded Output: tensor([[[-0.7872, -1.2312,  0.8621,  ..., -0.4186,  0.1538,  0.1275],\n",
      "         [-0.7872, -1.2312,  0.8621,  ..., -0.4186,  0.1538,  0.1275],\n",
      "         [-0.7872, -1.2312,  0.8621,  ..., -0.4186,  0.1538,  0.1275],\n",
      "         ...,\n",
      "         [-0.7872, -1.2312,  0.8621,  ..., -0.4186,  0.1538,  0.1275],\n",
      "         [-0.7872, -1.2312,  0.8621,  ..., -0.4186,  0.1538,  0.1275],\n",
      "         [-0.7872, -1.2312,  0.8621,  ..., -0.4186,  0.1538,  0.1275]],\n",
      "\n",
      "        [[-0.5446,  0.7237,  0.0139,  ..., -0.1148, -0.1133,  0.2608],\n",
      "         [-0.5446,  0.7237,  0.0139,  ..., -0.1148, -0.1133,  0.2608],\n",
      "         [-0.5446,  0.7237,  0.0139,  ..., -0.1148, -0.1133,  0.2608],\n",
      "         ...,\n",
      "         [-0.5446,  0.7237,  0.0139,  ..., -0.1148, -0.1133,  0.2608],\n",
      "         [-0.5446,  0.7237,  0.0139,  ..., -0.1148, -0.1133,  0.2608],\n",
      "         [-0.5446,  0.7237,  0.0139,  ..., -0.1148, -0.1133,  0.2608]],\n",
      "\n",
      "        [[-0.0079, -0.5118,  0.7526,  ..., -0.5490, -0.6351,  0.7230],\n",
      "         [-0.0079, -0.5118,  0.7526,  ..., -0.5490, -0.6351,  0.7230],\n",
      "         [-0.0079, -0.5118,  0.7526,  ..., -0.5490, -0.6351,  0.7230],\n",
      "         ...,\n",
      "         [-0.0079, -0.5118,  0.7526,  ..., -0.5490, -0.6351,  0.7230],\n",
      "         [-0.0079, -0.5118,  0.7526,  ..., -0.5490, -0.6351,  0.7230],\n",
      "         [-0.0079, -0.5118,  0.7526,  ..., -0.5490, -0.6351,  0.7230]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1593,  0.8406, -0.4789,  ..., -0.3038,  1.0063,  0.8339],\n",
      "         [ 0.1593,  0.8406, -0.4789,  ..., -0.3038,  1.0063,  0.8339],\n",
      "         [ 0.1593,  0.8406, -0.4789,  ..., -0.3038,  1.0063,  0.8339],\n",
      "         ...,\n",
      "         [ 0.1593,  0.8406, -0.4789,  ..., -0.3038,  1.0063,  0.8339],\n",
      "         [ 0.1593,  0.8406, -0.4789,  ..., -0.3038,  1.0063,  0.8339],\n",
      "         [ 0.1593,  0.8406, -0.4789,  ..., -0.3038,  1.0063,  0.8339]],\n",
      "\n",
      "        [[ 0.1763,  0.5334, -0.3609,  ...,  0.3169,  0.3431,  0.2275],\n",
      "         [ 0.1763,  0.5334, -0.3609,  ...,  0.3169,  0.3431,  0.2275],\n",
      "         [ 0.1763,  0.5334, -0.3609,  ...,  0.3169,  0.3431,  0.2275],\n",
      "         ...,\n",
      "         [ 0.1763,  0.5334, -0.3609,  ...,  0.3169,  0.3431,  0.2275],\n",
      "         [ 0.1763,  0.5334, -0.3609,  ...,  0.3169,  0.3431,  0.2275],\n",
      "         [ 0.1763,  0.5334, -0.3609,  ...,  0.3169,  0.3431,  0.2275]],\n",
      "\n",
      "        [[ 0.1501, -0.2659,  0.6324,  ..., -0.8022, -0.3876,  0.0243],\n",
      "         [ 0.1501, -0.2659,  0.6324,  ..., -0.8022, -0.3876,  0.0243],\n",
      "         [ 0.1501, -0.2659,  0.6324,  ..., -0.8022, -0.3876,  0.0243],\n",
      "         ...,\n",
      "         [ 0.1501, -0.2659,  0.6324,  ..., -0.8022, -0.3876,  0.0243],\n",
      "         [ 0.1501, -0.2659,  0.6324,  ..., -0.8022, -0.3876,  0.0243],\n",
      "         [ 0.1501, -0.2659,  0.6324,  ..., -0.8022, -0.3876,  0.0243]]],\n",
      "       grad_fn=<ExpandBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class SensorEmbeddingLayer(nn.Module):\n",
    "    \"\"\"Embedding layer for sensor features.\"\"\"\n",
    "\n",
    "    def __init__(self, num_sensor: int, time_length: int, dim_embedding: int):\n",
    "        super(SensorEmbeddingLayer, self).__init__()\n",
    "        self.num_sensor = num_sensor\n",
    "        self.embedding_size = time_length\n",
    "        self.dim_embedding = dim_embedding\n",
    "\n",
    "        # Define the embedding layer\n",
    "        self.sensor_embedding = nn.Linear(time_length, dim_embedding)\n",
    "\n",
    "    def forward(self, sensor_matrix: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply sensor embedding to the input sensor matrix.\n",
    "        \n",
    "        Parameters:\n",
    "        sensor_matrix (torch.Tensor): Input tensor of shape (num_sensor, embedding_size)\n",
    "        \n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor of shape (num_sensor, embedding_size, dim_embedding)\n",
    "        \"\"\"\n",
    "        # Apply the embedding layer to each sensor in the matrix\n",
    "        embedded_matrix = self.sensor_embedding(sensor_matrix)\n",
    "        \n",
    "        # Expand the dimensions to match the desired output shape\n",
    "        embedded_matrix = embedded_matrix.unsqueeze(1).expand(-1, self.embedding_size, -1)\n",
    "        \n",
    "        return embedded_matrix\n",
    "\n",
    "# Example usage\n",
    "num_sensor = 37\n",
    "embedding_size = length_time\n",
    "dim_embedding = 32\n",
    "\n",
    "# Create the sensor embedding layer\n",
    "sensor_embedding_layer = SensorEmbeddingLayer(num_sensor, embedding_size, dim_embedding)\n",
    "\n",
    "\n",
    "# Get the embedded output\n",
    "sensor_embedded_output = sensor_embedding_layer(data_1)\n",
    "\n",
    "print(\"Embedded Output Shape:\", sensor_embedded_output.shape)\n",
    "print(\"Embedded Output:\", sensor_embedded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIME EMBEDDING LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Embedded Output Shape: torch.Size([1, 50, 32])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import Any, Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BigBirdConfig, MambaConfig\n",
    "\n",
    "class TimeEmbeddingLayer(nn.Module):\n",
    "    \"\"\"Embedding layer for time features.\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_size: int, is_time_delta: bool = False):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.is_time_delta = is_time_delta\n",
    "\n",
    "        self.w = nn.Parameter(torch.empty(1, self.embedding_size))\n",
    "        self.phi = nn.Parameter(torch.empty(1, self.embedding_size))\n",
    "\n",
    "        nn.init.xavier_uniform_(self.w)\n",
    "        nn.init.xavier_uniform_(self.phi)\n",
    "\n",
    "    def forward(self, time_stamps: torch.Tensor) -> Any:\n",
    "        \"\"\"Apply time embedding to the input time stamps.\"\"\"\n",
    "        if self.is_time_delta:\n",
    "            # If the time_stamps represent time deltas, we calculate the deltas.\n",
    "            # This is equivalent to the difference between consecutive elements.\n",
    "            time_stamps = torch.cat(\n",
    "                (time_stamps[:, 0:1] * 0, time_stamps[:, 1:] - time_stamps[:, :-1]),\n",
    "                dim=-1,\n",
    "            )\n",
    "        time_stamps = time_stamps.float()\n",
    "        time_stamps_expanded = time_stamps.unsqueeze(-1)\n",
    "        next_input = time_stamps_expanded * self.w + self.phi\n",
    "\n",
    "        return torch.sin(next_input)\n",
    "    \n",
    "# Example usage\n",
    "\n",
    "time_layer = TimeEmbeddingLayer(dim_embedding, is_time_delta=False)\n",
    "\n",
    "# Get the embedded output\n",
    "time_embedded_output = time_layer(time)\n",
    "\n",
    "print(\"Time Embedded Output Shape:\", time_embedded_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STATIC EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Embedded Output Shape: torch.Size([32])\n",
      "Static Embedded Output: tensor([-0.3539, -0.0950, -0.2146, -0.1592, -0.6021, -0.5876,  0.1616,  0.3047,\n",
      "        -0.2513,  0.3401,  0.4000,  0.1131,  0.1653, -0.0472, -1.0387,  0.3853,\n",
      "        -0.1978,  0.1301, -0.0531,  0.6286,  0.3585, -0.0314, -0.3951,  0.8722,\n",
      "         0.2968, -0.0645,  0.2482, -0.4026, -0.4583, -0.4860, -0.2026,  0.3073],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class StaticEmbeddings(nn.Module):\n",
    "    \"\"\"Embedding layer for static features.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, embedding_dim: int):\n",
    "        super(StaticEmbeddings, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Define the embedding layer\n",
    "        self.embedding_layer = nn.Linear(input_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, static_features: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply embedding to the input static features.\n",
    "        \n",
    "        Parameters:\n",
    "        static_features (torch.Tensor): Input tensor of shape (batch_size, input_dim)\n",
    "        \n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor of shape (batch_size, embedding_dim)\n",
    "        \"\"\"\n",
    "        # Apply the embedding layer\n",
    "        embedded_features = self.embedding_layer(static_features)\n",
    "        \n",
    "        return embedded_features\n",
    "\n",
    "# Example usage\n",
    "input_dim = static.shape[1]\n",
    "embedding_dim = 32  # Ensure this matches the desired embedding dimension\n",
    "\n",
    "# Create the static embedding layer\n",
    "static_embedding_layer = StaticEmbeddings(input_dim, embedding_dim)\n",
    "\n",
    "# Get the embedded output\n",
    "static_embedded_output = static_embedding_layer(static_1)\n",
    "\n",
    "print(\"Static Embedded Output Shape:\", static_embedded_output.shape)\n",
    "print(\"Static Embedded Output:\", static_embedded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOTAL EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Embedded Output Shape: torch.Size([37, 50, 32])\n",
      "Combined Embedded Output: tensor([[[ 1.4674e-01, -5.3012e-01, -2.0223e+00,  ..., -6.0152e-01,\n",
      "           1.4407e+00, -1.7751e+00],\n",
      "         [ 5.3187e-01, -1.7666e+00, -5.4897e-01,  ...,  2.5357e-01,\n",
      "           1.6419e+00, -9.6679e-01],\n",
      "         [ 7.5946e-01, -1.2530e+00, -2.2520e+00,  ...,  6.7409e-01,\n",
      "           4.9242e-01, -1.6938e+00],\n",
      "         ...,\n",
      "         [-8.5112e-01, -3.2267e-01, -2.0749e+00,  ..., -6.5844e-01,\n",
      "           9.8222e-01, -7.2803e-01],\n",
      "         [ 2.8971e-01, -1.8018e+00, -3.1125e-01,  ...,  3.7465e-02,\n",
      "          -9.1286e-03, -2.0416e-01],\n",
      "         [ 4.9728e-01, -5.7990e-01, -1.9952e+00,  ...,  3.1725e-01,\n",
      "           5.7610e-01, -1.7324e+00]],\n",
      "\n",
      "        [[-4.0913e-01,  1.3280e-01, -1.2357e+00,  ..., -8.7793e-01,\n",
      "           1.5883e+00, -1.2788e+00],\n",
      "         [-2.3999e-02, -1.1037e+00,  2.3760e-01,  ..., -2.2842e-02,\n",
      "           1.7895e+00, -4.7042e-01],\n",
      "         [ 2.0359e-01, -5.9005e-01, -1.4654e+00,  ...,  3.9769e-01,\n",
      "           6.4000e-01, -1.1975e+00],\n",
      "         ...,\n",
      "         [-1.4070e+00,  3.4026e-01, -1.2883e+00,  ..., -9.3484e-01,\n",
      "           1.1298e+00, -2.3166e-01],\n",
      "         [-2.6616e-01, -1.1388e+00,  4.7532e-01,  ..., -2.3894e-01,\n",
      "           1.3845e-01,  2.9221e-01],\n",
      "         [-5.8594e-02,  8.3030e-02, -1.2086e+00,  ...,  4.0839e-02,\n",
      "           7.2368e-01, -1.2361e+00]],\n",
      "\n",
      "        [[-3.3626e-01,  6.2111e-01, -8.8363e-01,  ...,  9.7224e-01,\n",
      "           1.1022e+00, -2.4805e+00],\n",
      "         [ 4.8873e-02, -6.1536e-01,  5.8970e-01,  ...,  1.8273e+00,\n",
      "           1.3033e+00, -1.6721e+00],\n",
      "         [ 2.7646e-01, -1.0174e-01, -1.1133e+00,  ...,  2.2479e+00,\n",
      "           1.5387e-01, -2.3992e+00],\n",
      "         ...,\n",
      "         [-1.3341e+00,  8.2856e-01, -9.3620e-01,  ...,  9.1532e-01,\n",
      "           6.4367e-01, -1.4334e+00],\n",
      "         [-1.9329e-01, -6.5053e-01,  8.2742e-01,  ...,  1.6112e+00,\n",
      "          -3.4767e-01, -9.0951e-01],\n",
      "         [ 1.4278e-02,  5.7134e-01, -8.5654e-01,  ...,  1.8910e+00,\n",
      "           2.3755e-01, -2.4378e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.8693e-01,  9.7070e-01, -2.1377e-02,  ..., -3.8744e-01,\n",
      "           2.2607e+00, -2.1608e+00],\n",
      "         [ 1.1721e+00, -2.6578e-01,  1.4520e+00,  ...,  4.6765e-01,\n",
      "           2.4618e+00, -1.3525e+00],\n",
      "         [ 1.3997e+00,  2.4784e-01, -2.5103e-01,  ...,  8.8818e-01,\n",
      "           1.3123e+00, -2.0795e+00],\n",
      "         ...,\n",
      "         [-2.1093e-01,  1.1781e+00, -7.3947e-02,  ..., -4.4435e-01,\n",
      "           1.8021e+00, -1.1137e+00],\n",
      "         [ 9.2990e-01, -3.0094e-01,  1.6897e+00,  ...,  2.5155e-01,\n",
      "           8.1080e-01, -5.8985e-01],\n",
      "         [ 1.1375e+00,  9.2092e-01,  5.7144e-03,  ...,  5.3133e-01,\n",
      "           1.3960e+00, -2.1181e+00]],\n",
      "\n",
      "        [[ 1.2962e-01,  1.4508e+00,  1.8862e-01,  ...,  1.3990e-01,\n",
      "           1.0360e+00, -2.3220e+00],\n",
      "         [ 5.1475e-01,  2.1429e-01,  1.6619e+00,  ...,  9.9498e-01,\n",
      "           1.2371e+00, -1.5137e+00],\n",
      "         [ 7.4234e-01,  7.2791e-01, -4.1038e-02,  ...,  1.4155e+00,\n",
      "           8.7665e-02, -2.2407e+00],\n",
      "         ...,\n",
      "         [-8.6824e-01,  1.6582e+00,  1.3605e-01,  ...,  8.2982e-02,\n",
      "           5.7747e-01, -1.2749e+00],\n",
      "         [ 2.7259e-01,  1.7912e-01,  1.8997e+00,  ...,  7.7888e-01,\n",
      "          -4.1388e-01, -7.5105e-01],\n",
      "         [ 4.8016e-01,  1.4010e+00,  2.1571e-01,  ...,  1.0587e+00,\n",
      "           1.7135e-01, -2.2793e+00]],\n",
      "\n",
      "        [[-3.8431e-01,  1.9709e-01, -4.9621e-01,  ...,  6.2745e-02,\n",
      "           1.3765e+00, -8.5328e-01],\n",
      "         [ 8.1602e-04, -1.0394e+00,  9.7712e-01,  ...,  9.1783e-01,\n",
      "           1.5777e+00, -4.4939e-02],\n",
      "         [ 2.2841e-01, -5.2576e-01, -7.2587e-01,  ...,  1.3384e+00,\n",
      "           4.2818e-01, -7.7199e-01],\n",
      "         ...,\n",
      "         [-1.3822e+00,  4.0455e-01, -5.4878e-01,  ...,  5.8317e-03,\n",
      "           9.1799e-01,  1.9383e-01],\n",
      "         [-2.4135e-01, -1.0745e+00,  1.2148e+00,  ...,  7.0173e-01,\n",
      "          -7.3360e-02,  7.1769e-01],\n",
      "         [-3.3779e-02,  1.4732e-01, -4.6912e-01,  ...,  9.8152e-01,\n",
      "           5.1187e-01, -8.1058e-01]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class CombinedEmbeddings(nn.Module):\n",
    "    \"\"\"Combined embedding layer for sensor, time, and static features.\"\"\"\n",
    "\n",
    "    def __init__(self, num_sensor: int, time_lenght: int, dim_embedding: int, static_input_dim: int, is_time_delta: bool = False):\n",
    "        super(CombinedEmbeddings, self).__init__()\n",
    "        \n",
    "        # Initialize sensor embedding layer\n",
    "        self.sensor_embedding_layer = SensorEmbeddingLayer(num_sensor, time_lenght, dim_embedding)\n",
    "        \n",
    "        # Initialize time embedding layer\n",
    "        self.time_embedding_layer = TimeEmbeddingLayer(dim_embedding, is_time_delta)\n",
    "        \n",
    "        # Initialize static embedding layer\n",
    "        self.static_embedding_layer = StaticEmbeddings(static_input_dim, dim_embedding)\n",
    "\n",
    "    def forward(self, sensor_matrix: torch.Tensor, time_stamps: torch.Tensor, static_features: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply combined embeddings to the input sensor matrix, time stamps, and static features.\n",
    "        \n",
    "        Parameters:\n",
    "        sensor_matrix (torch.Tensor): Input tensor of shape (num_sensor, sensor_embedding_size)\n",
    "        time_stamps (torch.Tensor): Input tensor of shape (1, time_embedding_size)\n",
    "        static_features (torch.Tensor): Input tensor of shape (batch_size, static_input_dim)\n",
    "        \n",
    "        Returns:\n",
    "        torch.Tensor: Concatenated output tensor of shape (batch_size, combined_embedding_dim)\n",
    "        \"\"\"\n",
    "        # Apply sensor embedding\n",
    "        sensor_embedded = self.sensor_embedding_layer(sensor_matrix) # output shape (num_sensor, time_lenght, dim_embedding)\n",
    "        \n",
    "        # Apply time embedding\n",
    "        time_embedded = self.time_embedding_layer(time_stamps) # output shape (1, time_lenght, dim_embedding)\n",
    "        time_embedded = time_embedded.expand(sensor_embedded.shape) # transform to shape (num_sensor, time_lenght, dim_embedding)\n",
    "        \n",
    "        # Apply static embedding\n",
    "        static_embedded = self.static_embedding_layer(static_features) # output shape (dim_embedding)\n",
    "        static_embedded = static_embedded.unsqueeze(0).unsqueeze(0).expand(sensor_embedded.shape) # transform to shape (num_sensor, time_lenght, dim_embedding)\n",
    "        \n",
    "        # Combine all embeddings by adding them together\n",
    "        combined_embedding = sensor_embedded + time_embedded + static_embedded\n",
    "        \n",
    "        return combined_embedding\n",
    "\n",
    "# Example usage\n",
    "combined_embedding_layer = CombinedEmbeddings(num_sensor, embedding_size, dim_embedding, input_dim, is_time_delta=False) \n",
    "\n",
    "# Get the combined embedded output\n",
    "combined_embedded_output = combined_embedding_layer(data_1, time, static_1)\n",
    "\n",
    "print(\"Combined Embedded Output Shape:\", combined_embedded_output.shape)\n",
    "print(\"Combined Embedded Output:\", combined_embedded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAMBA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
